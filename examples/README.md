# Example Highlights

## Hearing

A cochlear implant processor simulation of "I am awake" speech sample from Breaking Bad. This demonstrates the auditory experience of basic audio processing for CIs—Not representative of state of the art experiences.

https://github.com/user-attachments/assets/069b87de-24ea-42c5-a768-64e30dbde4d4

## Music

A rendering of piano and drums group playing "Bella Ciao" tune. Sounds from instruments are generated synthetically. Drums from white noise, frequency filters, simple sine waves, and simple percussive energy envelopes. Piano from the same tools, but enhanced further with frequency parameters extracted from real audio samples, and a more realistic percussive energy envelope.

https://github.com/user-attachments/assets/7ae9d3a3-1c47-4caa-8d10-1eb5cc248b22

## Speech

A predictive classification of who's speaking—Biden or Trump?—during the 2024 presidential debate. Many metrics were computed on speech samples from both individuals, and two machine learning models were fitted to the metrics data. The multi-dimensional data had strong clustering structures, which yielded highly accurate predictions of who's speaking. Biden's speech was more tightly monotonous, while Trump's speech was more loosely dynamic, giving greater contrasts between their spectral qualities.

[Speaker Classification Plot](https://raw.githubusercontent.com/wjonasreger/AudioSigPy/main/imgs/biden-trump.png)

For those of you who read this far, I appreciate you :)
